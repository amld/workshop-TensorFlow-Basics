{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"name": "1_data", "version": "0.3.2", "provenance": [{"file_id": "https://github.com/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/1_qd_data.ipynb", "timestamp": 1544434140243}], "collapsed_sections": [], "toc_visible": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}}, "cells": [{"metadata": {"colab_type": "text", "id": "rtiYQNdwGeFs"}, "cell_type": "markdown", "source": ["# QuickDraw Data\n", "\n", "If machine learning is rocket science then data is your fuel! So before\n", "doing anything we will have a close look at the data available and spend\n", "some time bringing it into the \"right\" form (i.e.\n", "[tf.train.Example](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/train/Example)).\n", "\n", "That's why we start by spending quite a lot of time on this notebook, downloading\n", "the data, understanding it, and transforming it into the right format for\n", "Tensorflow.\n", "\n", "The data used in this workshop is taken from Google's quickdraw (click on\n", "the images to see loads of examples):\n", "\n", "https://quickdraw.withgoogle.com/data\n", "\n", "We will download the data below."]}, {"metadata": {"id": "wLhwRewZcVl8", "colab_type": "text"}, "cell_type": "markdown", "source": ["## Init"]}, {"metadata": {"id": "Sv44gRqoyCBi", "colab_type": "text"}, "cell_type": "markdown", "source": ["First, we'll choose where our data should be stored.\n", "\n", "If you choose a path under **\"/content/gdrive/My Drive\"** then data will be stored in your Google drive and persisted across VM starts (preferrable)."]}, {"metadata": {"id": "twZEazVEiS4W", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["data_path = '/content/gdrive/My Drive/amld_data'\n", "# Alternatively, you can also store the data in a local directory. This method\n", "# will also work when running the notebook in Jupyter instead of Colab.\n", "# data_path = './amld_data'"], "execution_count": null, "outputs": []}, {"metadata": {"id": "HPH_5nWRfTfH", "colab_type": "code", "outputId": "f91c2beb-7ed7-4d0a-c38e-98a9b5f0c55f", "executionInfo": {"status": "ok", "timestamp": 1548506053804, "user_tz": -60, "elapsed": 683, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 55}}, "cell_type": "code", "source": ["if data_path.startswith('/content/gdrive/'):\n", "  from google.colab import drive\n", "  assert data_path.startswith('/content/gdrive/My Drive/'), \\\n", "         'Google Drive paths must start with \"/content/gdrive/My Drive/\"!'\n", "  drive.mount('/content/gdrive')\n", "\n", "if data_path.startswith('gs://'):\n", "  from google.colab import auth\n", "  auth.authenticate_user()"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506055618, "user_tz": -60, "elapsed": 2478, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "EBkp94O9GeFt", "outputId": "38e4ab53-bc67-47e2-ba4d-1bb517f81771", "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["import base64, collections, io, itertools, functools, json, os, random, re, textwrap, time, urllib\n", "import numpy as np\n", "import pandas as pd\n", "import tensorflow as tf\n", "from matplotlib import pyplot\n", "from PIL import Image, ImageDraw\n", "from IPython import display\n", "from six.moves.urllib import request\n", "from xml.dom import minidom\n", "\n", "# Always make sure you are using running the expected version.\n", "# There are considerable differences between versions...\n", "# Tested with 1.12.0\n", "tf.__version__"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "text", "id": "eY81Xe9CGeFz"}, "cell_type": "markdown", "source": ["## Get the data\n", "\n", "In this section we download a set of raw data files from the web."]}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506055620, "user_tz": -60, "elapsed": 2460, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "ujcwY2WRGeFz", "outputId": "156b1f34-c40d-41ab-8559-708c2b4d92c6", "colab": {"base_uri": "https://localhost:8080/", "height": 577}}, "cell_type": "code", "source": ["# Retrieve list of categories.\n", "\n", "def list_bucket(bucket, regexp='.*'):\n", "    \"\"\"Returns a (filtered) list of Keys in specified GCS bucket.\"\"\"\n", "    keys = []\n", "    fh = request.urlopen('https://storage.googleapis.com/%s' % bucket)\n", "    content = minidom.parseString(fh.read())\n", "    for e in content.getElementsByTagName('Contents'):\n", "        key = e.getElementsByTagName('Key')[0].firstChild.data\n", "        if re.match(regexp, key):\n", "            keys.append(key)\n", "    return keys\n", "\n", "all_ndjsons = list_bucket('quickdraw_dataset', '.*ndjson$')\n", "print('available: (%d)' % len(all_ndjsons))\n", "print('\\n'.join(textwrap.wrap(\n", "    '|'.join([key.split('/')[-1].split('.')[0] for key in all_ndjsons]),\n", "    width=100)))"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "id": "MjaUHJ7zGeF3", "colab": {}}, "cell_type": "code", "source": ["# Mini group of two animals.\n", "pets = ['cat', 'dog']\n", "\n", "# Somewhat larger group of zoo animals.\n", "zoo = ['camel', 'crocodile', 'dolphin', 'elephant', 'flamingo', 'giraffe',\n", "       'kangaroo', 'lion', 'monkey', 'penguin', 'rhinoceros']\n", "\n", "# Even larger group of all animals.\n", "animals = ['ant', 'bat', 'bear', 'bee', 'bird', 'butterfly', 'camel', 'cat',\n", "           'cow', 'crab', 'crocodile', 'dog', 'dolphin', 'dragon', 'duck',\n", "           'elephant', 'fish', 'flamingo', 'frog', 'giraffe', 'hedgehog',\n", "           'horse', 'kangaroo', 'lion', 'lobster', 'monkey', 'mosquito',\n", "           'mouse', 'octopus', 'owl', 'panda', 'parrot', 'penguin', 'pig',\n", "           'rabbit', 'raccoon', 'rhinoceros', 'scorpion', 'sea turtle', 'shark',\n", "           'sheep', 'snail', 'snake', 'spider', 'squirrel', 'swan']"], "execution_count": null, "outputs": []}, {"metadata": {"id": "6Df5Br4Pyb9b", "colab_type": "text"}, "cell_type": "markdown", "source": ["Create your own group -- the more categories you include the more challenging the classification task will be..."]}, {"metadata": {"id": "V-wVsOV4yZlA", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Choose one of above groups for remainder of workshop.\n", "# Note: This will result in ~100MB of download per class.\n", "# The \"dataset_name\" will be used to construct directories containing the data.\n", "labels, dataset_name = zoo, 'zoo'"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506081354, "user_tz": -60, "elapsed": 28178, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "tmzXx5skGeF5", "outputId": "3b615f70-ab47-4d28-a941-acdb799b624d", "colab": {"base_uri": "https://localhost:8080/", "height": 703}}, "cell_type": "code", "source": ["# Download above chosen group.\n", "\n", "def valid_ndjson(filename):\n", "  \"\"\"Checks presence + completeness of .ndjson file.\"\"\"\n", "  try:\n", "    json.loads(tf.gfile.Open(filename).readlines()[-1])\n", "    return True\n", "  except (ValueError, IOError):\n", "    return False\n", "\n", "def retrieve(bucket, key, filename):\n", "  \"\"\"Returns a file specified by its Key from a GCS bucket.\"\"\"\n", "  url = 'https://storage.googleapis.com/%s/%s' % (\n", "    bucket, urllib.parse.quote(key))\n", "  print('\\n' + url)\n", "  if not tf.gfile.Exists(filename):\n", "    with tf.gfile.Open(filename, 'w') as f:\n", "      f.write(request.urlopen(url).read())\n", "  while not valid_ndjson(filename):\n", "    print('*** Corrupted download (%.2f MB), retrying...' % (os.path.getsize(filename) / 2.**20))\n", "    with tf.gfile.Open(filename, 'w') as f:\n", "      f.write(request.urlopen(url).read())\n", "\n", "tf.gfile.MakeDirs(data_path)\n", "\n", "print('\\n%d labels:' % len(labels))\n", "\n", "for name in labels:\n", "  print(name, end=' ')\n", "  dst = '%s/%s.ndjson' % (data_path, name)\n", "  retrieve('quickdraw_dataset', 'full/simplified/%s.ndjson' % name, dst)\n", "  print('%.2f MB' % (tf.gfile.Stat(dst).length / 2.**20))\n", "\n", "print('\\nDONE :)')"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "text", "id": "ZO6tp_h-GeF8"}, "cell_type": "markdown", "source": ["## Inspect the data\n", "\n", "Let's find out what the format of the downloaded files is.\n", "\n", "First, we are going to enumerate them."]}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506084890, "user_tz": -60, "elapsed": 31699, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "Xb_2LxbMGeF_", "outputId": "fd8f6e75-e0e8-4728-bb1b-df942289bfcf", "colab": {"base_uri": "https://localhost:8080/", "height": 215}}, "cell_type": "code", "source": ["print('\\n'.join([\n", "    '%6.1fM : %s' % (tf.gfile.Stat(path).length/1024**2, path)\n", "    for path in tf.gfile.Glob('{}/*.ndjson'.format(data_path))\n", "]))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "HBz4Bn90yyWX", "colab_type": "text"}, "cell_type": "markdown", "source": ["Let's further explore what the `NDJSON` file format is."]}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506084892, "user_tz": -60, "elapsed": 31681, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "UCL46qhKGeGC", "outputId": "01c90695-3fb3-49c1-8290-908b1c046128", "colab": {"base_uri": "https://localhost:8080/", "height": 73}}, "cell_type": "code", "source": ["path = sorted(tf.gfile.Glob(os.path.join(data_path, '*.ndjson')))[0]\n", "print(tf.gfile.Open(path).read()[:1000] + '...')"], "execution_count": null, "outputs": []}, {"metadata": {"id": "tAVekUf8y7dx", "colab_type": "text"}, "cell_type": "markdown", "source": ["As we can see, it's a format that contains one JSON dictionary per line.\n", "\n", "Let's parse one single line."]}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506084893, "user_tz": -60, "elapsed": 31649, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "f6m9rZzjGeGG", "outputId": "44fb91ff-a6e9-40be-d71c-c837d9746e40", "colab": {"base_uri": "https://localhost:8080/", "height": 55}}, "cell_type": "code", "source": ["data_json = json.loads(tf.gfile.Open(path).readline())\n", "data_json.keys()"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506084895, "user_tz": -60, "elapsed": 31635, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "XKyZ2P4KGeGJ", "outputId": "83123708-94b5-4bbb-a5c6-cf5acb713760", "colab": {"base_uri": "https://localhost:8080/", "height": 107}}, "cell_type": "code", "source": ["# So we have some meta information...\n", "for k, v in data_json.items():\n", "  if k != 'drawing':\n", "    print('%20s   ->   %s' % (k, v))"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548506138953, "user_tz": -60, "elapsed": 1032, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "id": "S8uCmlQ_GeGN", "outputId": "01608920-deeb-4e78-d1e3-4a5c5e0f6368", "colab": {"base_uri": "https://localhost:8080/", "height": 73}}, "cell_type": "code", "source": ["# ...and the actual drawing.\n", "drawing = data_json['drawing']\n", "# The drawing consists of a series of strokes:\n", "print('Shapes:', [np.array(stroke).shape for stroke in drawing])\n", "print('Example stroke:', drawing[0])"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548457577172, "user_tz": 480, "elapsed": 59605, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "bb7XhpB4GeGQ", "outputId": "cbc6fdd9-39d3-4b7a-adf5-7c0aa9420745", "colab": {"base_uri": "https://localhost:8080/", "height": 347}}, "cell_type": "code", "source": ["# Draw the image -- the strokes all have have shape (2, n)\n", "# so the first index seems to be x/y coordinate:\n", "for stroke in drawing:\n", "  # Each array has X coordinates at [0, :] and Y coordinates at [1, :].\n", "  pyplot.plot(np.array(stroke[0]), -np.array(stroke[1]))\n", "# Would YOU recognize this drawing successfully?"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548457577174, "user_tz": 480, "elapsed": 59607, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "1wwxryjLGeGU", "outputId": "c6184887-cd86-4b16-f2c1-ff11f8a9f22e", "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "cell_type": "code", "source": ["# Some more code to load many sketches at once.\n", "# Let's ignore the difficult \"unrecognized\" sketches for now...\n", "# (i.e. unrecognized by the official quickdraw classifier)\n", "\n", "def convert(line):\n", "    \"\"\"Converts single JSON line and converts 'drawing' to list of np.array.\"\"\"\n", "    d = json.loads(line)\n", "    d['drawing'] = [np.array(stroke) for stroke in d['drawing']]\n", "    return d\n", "\n", "def loaditer(name, unrecognized=False):\n", "  \"\"\"Returns iterable of drawings in specified file.\n", "\n", "  Args:\n", "    name: Name of the downloaded object (e.g. \"elephant\").\n", "    unrecognized: Whether to include drawings that were not recognized\n", "        by Google AI (i.e. the hard ones).\n", "  \"\"\"\n", "  for line in tf.gfile.Open('%s/%s.ndjson' % (data_path, name)):\n", "    d = convert(line)\n", "    if d['recognized'] or unrecognized:\n", "      yield d\n", "\n", "def loadn(name, n, unrecognized=False):\n", "  \"\"\"Returns list of drawings.\n", "\n", "  Args:\n", "    name: Name of the downloaded object (e.g. \"elephant\").\n", "    n: Number of drawings to load.\n", "    unrecognized: Whether to include drawings that were not recognized\n", "        by Google AI (i.e. the hard ones).\n", "  \"\"\"\n", "  it = loaditer(name, unrecognized=unrecognized)\n", "  return list(itertools.islice(it, 0, n))\n", "\n", "n = 100\n", "print('Loading {} instances of \"{}\"...'.format(n, labels[0]), end='')\n", "sample = loadn(labels[0], 100)\n", "print('done.')"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548457578324, "user_tz": 480, "elapsed": 60756, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "-jzTKBt5GeGY", "outputId": "cc24d7f1-b48a-4931-d806-c879ed01f990", "colab": {"base_uri": "https://localhost:8080/", "height": 537}}, "cell_type": "code", "source": ["# Some more drawings...\n", "rows, cols = 3, 3\n", "pyplot.figure(figsize=(3*cols, 3*rows))\n", "for y in range(rows):\n", "  for x in range(cols):\n", "    i = y * cols + x\n", "    pyplot.subplot(rows, cols, i + 1)\n", "    for stroke in sample[i]['drawing']:\n", "      pyplot.plot(np.array(stroke[0]), -np.array(stroke[1]))"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "text", "id": "DF93HB1aGeGb"}, "cell_type": "markdown", "source": ["## Rasterize\n", "\n", "Idea: After converting the raw drawing data into rasterized images, we can\n", "use [MNIST](https://www.tensorflow.org/get_started/mnist/beginners)-like\n", "image processing to classify the drawings."]}, {"metadata": {"colab_type": "code", "id": "AVsC-4hcGeGc", "colab": {}}, "cell_type": "code", "source": ["def dict_to_img(drawing, img_sz=64, lw=3, maximize=True):\n", "  \"\"\"Converts QuickDraw data to quadratic rasterized image.\n", "  \n", "  Args:\n", "    drawing: Dictionary instance of QuickDraw dataset.\n", "    img_sz: Size output image (in pixels).\n", "    lw: Line width (in pixels).\n", "    maximize: Whether to maximize drawing within image pixels.\n", "    \n", "  Returns:\n", "    A PIL.Image with the rasterized drawing.\n", "  \"\"\"\n", "  img = Image.new('L', (img_sz, img_sz))\n", "  draw = ImageDraw.Draw(img)\n", "  lines = np.array([\n", "      stroke[0:2, i:i+2]\n", "      for stroke in drawing['drawing']\n", "      for i in range(stroke.shape[1] - 1)\n", "  ], dtype=np.float32)\n", "  if maximize:\n", "    for i in range(2):\n", "      min_, max_ = lines[:,i,:].min() * 0.95, lines[:,i,:].max() * 1.05\n", "      lines[:,i,:] = (lines[:,i,:] - min_) / max(max_ - min_, 1)\n", "  else:\n", "    lines /= 1024\n", "  for line in lines:\n", "    draw.line(tuple(line.T.reshape((-1,)) * img_sz), fill='white', width=lw)\n", "  return img"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548457598663, "user_tz": 480, "elapsed": 939, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "K4GzMB12GeGf", "outputId": "2b5b5f6b-41fc-4847-ea19-19785db6fcc7", "colab": {"base_uri": "https://localhost:8080/", "height": 742}}, "cell_type": "code", "source": ["# Show some examples.\n", "\n", "def showimg(img):\n", "  \"\"\"Shows an image with an inline HTML <img> tag.\n", "  \n", "  Args:\n", "    img: Can be a PIL.Image or a numpy.ndarray.\n", "  \"\"\"\n", "  if isinstance(img, np.ndarray):\n", "    img = Image.fromarray(img, 'L')\n", "  b = io.BytesIO()\n", "  img.convert('RGB').save(b, format='png')\n", "  enc = base64.b64encode(b.getvalue()).decode('utf-8')\n", "  display.display(display.HTML(\n", "      '<img src=\"data:image/png;base64,%s\">' % enc))\n", "\n", "# Fetch some images + shuffle order.\n", "rows, cols = len(labels), 10\n", "n_per_class = rows * cols // len(labels) + 1\n", "drawings_list = [drawing for name in labels\n", "                 for drawing in loadn(name, cols)]\n", "\n", "# Create mosaic of rendered images.\n", "lw = 4\n", "img_sz = 64\n", "tableau = np.zeros((img_sz * rows, img_sz * cols), dtype=np.uint8)\n", "for y in range(rows):\n", "  for x in range(cols):\n", "    i = y * cols + x\n", "    img = dict_to_img(drawings_list[i], img_sz=img_sz, lw=lw, maximize=True)\n", "    tableau[y*img_sz:(y+1)*img_sz,\n", "            x*img_sz:(x+1)*img_sz] = np.asarray(img)\n", "\n", "showimg(tableau)\n", "print('{} samples of : {}'.format(cols, ' '.join(labels)))"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "text", "id": "gW40he1tGeGi"}, "cell_type": "markdown", "source": ["## Protobufs and tf.train.Example\n", "\n", "Tensorflow's \"native\" format for data storage is the `tf.train.Example`\n", "[protocol buffer](https://en.wikipedia.org/wiki/Protocol_Buffers).\n", "\n", "In this section we briefly explore the API needed to access the data\n", "inside the `tf.train.Example` protocol buffer. It's **not necessary** to read\n", "through the\n", "[Protocol Buffer Basics: Python - documentation](https://developers.google.com/protocol-buffers/docs/pythontutorial)."]}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548457598946, "user_tz": 480, "elapsed": 1211, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "BB8g-Tb1GeGn", "outputId": "dde19f31-43ce-4be1-d476-83d173f5fcdd", "colab": {"base_uri": "https://localhost:8080/", "height": 425}}, "cell_type": "code", "source": ["# Create a new (empty) instance.\n", "example = tf.train.Example()\n", "# (empty example will print nothing)\n", "print(example)\n", "# An example contains a map from feature name to \"Feature\".\n", "# Every \"Feature\" contains a list of elements of the same\n", "# type, which is one of:\n", "# - bytes_list (similar to Python's \"str\")\n", "# - float_list (float number)\n", "# - int64_list (integer number)\n", "\n", "# These values can be accessed as follows (no need to understand\n", "# details):\n", "\n", "# Add float value \"3.1416\" to feature \"magic_numbers\"\n", "example.features.feature['magic_numbers'].float_list.value.append(3.1416)\n", "# Add some more values to the float list \"magic_numbers\".\n", "example.features.feature['magic_numbers'].float_list.value.extend([2.7183, 1.4142, 1.6180])\n", "\n", "### YOUR ACTION REQUIRED:\n", "# Create a second feature named \"adversaries\" and add the elements\n", "# b'Alice' and b'Bob'.\n", "example.features.feature['adversaries'].\n", "\n", "# This will now print a serialized representation of our protocol buffer\n", "# with features \"magic_numbers\" and \"adversaries\" set...\n", "print(example)\n", "\n", "# .. et voila : that's all you need to know about protocol buffers\n", "# for this workshop."], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "text", "id": "33imDs6YGeGq"}, "cell_type": "markdown", "source": ["## Create datasets\n", "\n", "Now let's create a \"dataset\" of `tf.train.Example`\n", "[protocol buffers](https://developers.google.com/protocol-buffers/) (\"protos\").\n", "\n", "A single example will containt all the information we want to use for training for a drawing (i.e. rasterized\n", "image, label, and maybe other information).\n", "\n", "A dataset consists of non-overlapping sets of examples that will be used for\n", "training and evaluation of the classifier (the \"test\" set will be used for the\n", "final evaluation). Because these files can quickly become very large, we\n", "\"shard\" them into multiple smaller files of equal size."]}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548457688690, "user_tz": 480, "elapsed": 90945, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "Ef_i5QFWGeGq", "outputId": "377ae670-39f6-4b32-9002-747f25589ab9", "collapsed": true, "colab": {"base_uri": "https://localhost:8080/", "height": 204}}, "cell_type": "code", "source": ["# Let's first check how many [recognized=True] examples we have in each class.\n", "for name in labels:\n", "    print(name, len(list(tf.gfile.Open('%s/%s.ndjson' % (data_path, name)))), 'recognized', len(list(loaditer(name))))"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "id": "r4h9W4JvGeGt", "colab": {}}, "cell_type": "code", "source": ["# Helper code to create sharded recordio files.\n", "# (No need to read through this.)\n", "\n", "# Well... Since you continue to read through this cell, I could as\n", "# well explain in more detail what it is about :-)\n", "# Because we work with large amounts of data, we will create \"sharded\"\n", "# files, that is, we split a single dataset into a number of files, like\n", "# train-00000-of-00004, ..., train-00000-of-00005 (if we're using 5 shards).\n", "# This way we have smaller individual files, and we can also easily access\n", "# e.g. 20% of all data, or have 5 threads reading through the data\n", "# simultaneously. With large datasets, try to shard data into individual files\n", "# ~ 100 MB.\n", "\n", "# The code in this cell simply takes a list of iterators and then\n", "# randomly distributes the values returned by these iterators into sharded\n", "# datasets (e.g. a train/eval/test split).\n", "\n", "def rand_key(counts):\n", "  \"\"\"Returns a random key from \"counts\", using values as distribution.\"\"\"\n", "  r = random.randint(0, sum(counts.values()))\n", "  for key, count in counts.items():\n", "    if r > count or count == 0:\n", "      r -= count\n", "    else:\n", "      counts[key] -= 1\n", "      return key\n", "\n", "def get_split(i, splits):\n", "  \"\"\"Returns key from \"splits\" for iteration \"i\".\"\"\"\n", "  i %= sum(splits.values())\n", "  for split in sorted(splits):\n", "    if i < splits[split]:\n", "      return split\n", "    i -= splits[split]\n", "\n", "def make_counts(labels, total):\n", "  \"\"\"Generates counts for \"labels\" totaling \"total\".\"\"\"\n", "  counts = {}\n", "  for i, name in enumerate(labels):\n", "    counts[name] = total // (len(labels) - i)\n", "    total -= counts[name]\n", "  return counts\n", "\n", "def example_to_dict(example):\n", "  \"\"\"Converts a tf.train.Example to a dictionary.\"\"\"\n", "  example_dict = {}\n", "  for name, value in example.features.feature.items():\n", "    if value.HasField('bytes_list'):\n", "      value = value.bytes_list.value\n", "    elif value.HasField('int64_list'):\n", "      value = value.int64_list.value\n", "    elif value.HasField('float_list'):\n", "      value = value.float_list.value\n", "    else:\n", "      raise 'Unknown *_list type!'\n", "    if len(value) == 1:\n", "      example_dict[name] = value[0]\n", "    else:\n", "      example_dict[name] = np.array(value)\n", "  return example_dict\n", "\n", "def make_sharded_files(make_example, path, labels, iters, counts, splits,\n", "                       shards=10, overwrite=False, report_dt=10, make_df=False):\n", "  \"\"\"Create sharded dataset from \"iters\".\n", "\n", "  Args:\n", "    make_example: Converts object returned by elements of \"iters\"\n", "        to tf.train.Example() proto.\n", "    path: Directory that will contain recordio files.\n", "    labels: Names of labels, will be written to \"labels.txt\".\n", "    iters: List of iterables returning drawing objects.\n", "    counts: Dictionary mapping class to number of examples.\n", "    splits: Dictionary mapping filename to multiple of examples. For example,\n", "        splits=dict(a=2, b=1) will result in two exampels being written to \"a\"\n", "        for every example being written to \"b\".\n", "    shards: Number of files to be created per split.\n", "    overwrite: Whether a pre-existing directory should be overwritten.\n", "    report_dt: Number of seconds between status updates (0=no updates).\n", "    make_df: Also write data as pandas.DataFrame - do NOT use this with very\n", "        large datasets that don't fit in memory!\n", "\n", "  Returns:\n", "    Total number of examples written to disk per split.\n", "  \"\"\"\n", "  assert len(iters) == len(labels)\n", "  # Prepare output.\n", "  if not os.path.exists(path):\n", "    os.makedirs(path)\n", "  paths = {\n", "      split: ['%s/%s-%05d-of-%05d' % (path, split, i, shards)\n", "              for i in range(shards)]\n", "      for split in splits\n", "  }\n", "  assert overwrite or not os.path.exists(paths.values()[0][0])\n", "  writers = {\n", "      split: [tf.python_io.TFRecordWriter(ps[i]) for i in range(shards)]\n", "      for split, ps in paths.items()\n", "  }\n", "  t0 = time.time()\n", "  examples_per_split = collections.defaultdict(int)\n", "  i, n = 0, sum(counts.values())\n", "  counts = dict(**counts)\n", "  rows = []\n", "  # Create examples.\n", "  while sum(counts.values()):\n", "    name = rand_key(counts)\n", "    split = get_split(i, splits)\n", "    writer = writers[split][examples_per_split[split] % shards]\n", "    label = labels.index(name)\n", "    example = make_example(label, next(iters[label]))\n", "    writer.write(example.SerializeToString())\n", "    if make_df:\n", "      example.features.feature['split'].bytes_list.value.append(split.encode('utf8'))\n", "      rows.append(example_to_dict(example))\n", "    examples_per_split[split] += 1\n", "    i += 1\n", "    if report_dt > 0 and time.time() - t0 > report_dt:\n", "      print('processed %d/%d (%.2f%%)' % (i, n, 100. * i / n))\n", "      t0 = time.time()\n", "  # Store results.\n", "  for split in splits:\n", "    for writer in writers[split]:\n", "      writer.close()\n", "  with open('%s/labels.txt' % path, 'w') as f:\n", "    f.write('\\n'.join(labels))\n", "  with open('%s/counts.json' % path, 'w') as f:\n", "    json.dump(examples_per_split, f)\n", "  if make_df:\n", "    df_path = '%s/dataframe.pkl' % path\n", "    print('Writing %s...' % df_path)\n", "    pd.DataFrame(rows).to_pickle(df_path)\n", "  return dict(**examples_per_split)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "Ecj5-3EGKXOd", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Create IMG dataset"]}, {"metadata": {"colab_type": "code", "id": "uPF9vIipGeGv", "colab": {}}, "cell_type": "code", "source": ["# Uses dict_to_img() from previous cell to create raster image.\n", "\n", "def make_example_img(label, drawing):\n", "  \"\"\"Converts QuickDraw dictionary to example with rasterized data.\n", "\n", "  Args:\n", "    label: Numerical representation of the label (e.g. \"0\" for labels[0]).\n", "    drawing: Dictionary with QuickDraw data.\n", "\n", "  Returns:\n", "    A tf.train.Example protocol buffer (with \"label\", \"img_64\", and additional\n", "    metadata features).\n", "  \"\"\"\n", "  example = tf.train.Example()\n", "  example.features.feature['label'].int64_list.value.append(label)\n", "  img_64 = np.asarray(dict_to_img(drawing, img_sz=64, lw=4, maximize=True)).reshape(-1)\n", "  example.features.feature['img_64'].int64_list.value.extend(img_64)\n", "  example.features.feature['countrycode'].bytes_list.value.append(drawing['countrycode'].encode())\n", "  example.features.feature['recognized'].int64_list.value.append(drawing['recognized'])\n", "  example.features.feature['word'].bytes_list.value.append(drawing['word'].encode())\n", "  ts = drawing['timestamp']\n", "  ts = time.mktime(time.strptime(ts[:ts.index('.')], '%Y-%m-%d %H:%M:%S'))\n", "  example.features.feature['timestamp'].int64_list.value.append(int(ts))\n", "  example.features.feature['key_id'].int64_list.value.append(int(drawing['key_id']))\n", "  return example"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548458056465, "user_tz": 480, "elapsed": 458684, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "ksR9Hw0DGeGy", "outputId": "07617d26-5152-4f7b-f043-fb29fc650651", "colab": {"base_uri": "https://localhost:8080/", "height": 425}}, "cell_type": "code", "source": ["# Create the (rasterized) dataset.\n", "\n", "path = '%s/%s_img' % (data_path, dataset_name)\n", "t0 = time.time()\n", "examples_per_split = make_sharded_files(\n", "    make_example=make_example_img,\n", "    path=path,\n", "    labels=labels,\n", "    iters=[loaditer(name) for name in labels],\n", "    # Creating 50k train, 10k eval, 20k test examples. Takes ~2min\n", "    # Note : Larger datasets take longer to generate and to train on, but\n", "    #        also lead to better classification results.\n", "    counts=make_counts(labels, 80000),\n", "    splits=dict(train=5, eval=1, test=2),\n", "    overwrite=True,\n", "    # Note : Set this to False when generating large datasets...\n", "    make_df=True,\n", ")\n", "\n", "### If you don't see the final output below, it's probably because your VM\n", "### has run out of memory and crashed !! This can happen with make_df=True ...\n", "\n", "print('stored data to \"%s\"' % path)\n", "print('generated %s examples in %d seconds' % (examples_per_split, time.time() - t0))"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "text", "id": "s-MmsFVFGeG1"}, "cell_type": "markdown", "source": ["### Create STROKE dataset\n", "\n", "This section creates another dataset of example protos that contain the raw\n", "stroke data, suitable for usage with a recurrent neural network."]}, {"metadata": {"colab_type": "code", "id": "c1SCR8h1GeG2", "colab": {}}, "cell_type": "code", "source": ["# Convert stroke coordinates into normalized relative coordinates,\n", "# one single list, and add a \"third dimension\" that indicates when\n", "# a new stroke starts.\n", "\n", "def dict_to_stroke(d):\n", "  norm = lambda x: (x - x.min()) / max(1, (x.max() - x.min()))\n", "  xy = np.concatenate([np.array(s, dtype=np.float32) for s in d['drawing']], axis=1)\n", "  z = np.zeros(xy.shape[1])\n", "  if len(d['drawing']) > 1:\n", "    z[np.cumsum(np.array(list(map(lambda x: x.shape[1], d['drawing'][:-1]))))] = 1\n", "  dxy = np.diff(norm(xy))\n", "  return np.concatenate([dxy, z.reshape((1, -1))[:, 1:]])"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "executionInfo": {"status": "ok", "timestamp": 1548458057070, "user_tz": 480, "elapsed": 459277, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "id": "QC1U8kZ8GeG4", "outputId": "84864424-f040-43c8-9ac8-adc8c2983398", "colab": {"base_uri": "https://localhost:8080/", "height": 347}}, "cell_type": "code", "source": ["# Visualize / control output of dict_to_stroke().\n", "\n", "stroke = dict_to_stroke(sample[0])\n", "# First 2 dimensions are normalized dx/dy coordinates\n", "# third dimension indicates \"new stroke\".\n", "xy = stroke[:2, :].cumsum(axis=1)\n", "pyplot.plot(xy[0,:], -xy[1,:])\n", "pxy = xy[:, stroke[2] != 0]\n", "# Indicate \"new stroke\" with a red circle.\n", "pyplot.plot(pxy[0], -pxy[1], 'ro');"], "execution_count": null, "outputs": []}, {"metadata": {"colab_type": "code", "id": "rxzZZyR9GeG8", "colab": {}}, "cell_type": "code", "source": ["# Uses dict_to_stroke() from previous cell to create raster image.\n", "\n", "def make_example_stroke(label, drawing):\n", "  \"\"\"Converts QuickDraw dictionary to example with stroke data.\n", "\n", "  Args:\n", "    label: Numerical representation of the label (e.g. \"0\" for labels[0]).\n", "    drawing: Dictionary with QuickDraw data.\n", "\n", "  Returns:\n", "    A tf.train.Example protocol buffer (with \"label\", \"stroke_x\", \"stroke_y\",\n", "    \"stroke_z\", and additional metadata features).\n", "  \"\"\"\n", "  example = tf.train.Example()\n", "  example.features.feature['label'].int64_list.value.append(label)\n", "  stroke = dict_to_stroke(drawing)\n", "  example.features.feature['stroke_x'].float_list.value.extend(stroke[0, :])\n", "  example.features.feature['stroke_y'].float_list.value.extend(stroke[1, :])\n", "  example.features.feature['stroke_z'].float_list.value.extend(stroke[2, :])\n", "  example.features.feature['stroke_len'].int64_list.value.append(stroke.shape[1])\n", "  example.features.feature['countrycode'].bytes_list.value.append(drawing['countrycode'].encode())\n", "  example.features.feature['recognized'].int64_list.value.append(drawing['recognized'])\n", "  example.features.feature['word'].bytes_list.value.append(drawing['word'].encode())\n", "  ts = drawing['timestamp']\n", "  ts = time.mktime(time.strptime(ts[:ts.index('.')], '%Y-%m-%d %H:%M:%S'))\n", "  example.features.feature['timestamp'].int64_list.value.append(int(ts))\n", "  example.features.feature['key_id'].int64_list.value.append(int(drawing['key_id']))\n", "  return example"], "execution_count": null, "outputs": []}, {"metadata": {"id": "A7LyQXCv3ADO", "colab_type": "code", "outputId": "3fef9cff-c4ba-4dcf-edc4-723d4a22e544", "executionInfo": {"status": "ok", "timestamp": 1548458126908, "user_tz": 480, "elapsed": 529100, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 153}}, "cell_type": "code", "source": ["path = '%s/%s_stroke' % (data_path, dataset_name)\n", "t0 = time.time()\n", "examples_per_split = make_sharded_files(\n", "    make_example=make_example_stroke,\n", "    path=path,\n", "    labels=labels,\n", "    iters=[loaditer(name) for name in labels],\n", "    # Creating 50k train, 10k eval, 20k test examples. Takes ~2min\n", "    # Note : You can improve \n", "    counts=make_counts(labels, 80000),\n", "    splits=dict(train=5, eval=1, test=2),\n", "    overwrite=True,\n", "    # Note : Set this to False when generating large datasets...\n", "    make_df=True,\n", ")\n", "\n", "print('stored data to \"%s\"' % path)\n", "print('generated %s examples in %d seconds' % (examples_per_split, time.time() - t0))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "Kqkg17PxIhrJ", "colab_type": "text"}, "cell_type": "markdown", "source": ["# ----- Optional part -----"]}, {"metadata": {"id": "V1oCjDZhb2do", "colab_type": "text"}, "cell_type": "markdown", "source": ["## Inspect data"]}, {"metadata": {"id": "8aUJmZuUb5JH", "colab_type": "code", "outputId": "5d2eacaa-bfbb-4d45-9a56-47763a84cc34", "executionInfo": {"status": "ok", "timestamp": 1548458129752, "user_tz": 480, "elapsed": 531940, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 1224}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Check out the files generated in $data_path\n", "\n", "# Note that you can also inspect the files in http://drive.google.com if you\n", "# used Drive as the destination.\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "jq3yJWKMcQdV", "colab_type": "code", "outputId": "78a64d7a-9a5b-4d7f-a11a-d4b4ae4854c5", "executionInfo": {"status": "ok", "timestamp": 1548506226685, "user_tz": -60, "elapsed": 1231, "user": {"displayName": "Bartek Wo\u0142owiec", "photoUrl": "https://lh3.googleusercontent.com/-rqHWU_6ELWo/AAAAAAAAAAI/AAAAAAAAAds/A35w6l3YZQk/s64/photo.jpg", "userId": "17371296089199980029"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 55}}, "cell_type": "code", "source": ["# Let's look at a single file of the sharded dataset.\n", "tf_record_path = '{}/{}_img/eval-00000-of-00010'.format(data_path, dataset_name)\n", "# YOUR ACTION REQUIRED:\n", "# Use tf.python_io.tf_record_iterator() to read a single record from the file\n", "# an assign it to the variable \"record\".\n", "# What datatype has this record?\n", "#record = ...\n", "#record\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "KSMXw1BzfyHg", "colab_type": "text"}, "cell_type": "markdown", "source": ["**Note**: \n", "The `tf.python_io` should only be used for data processing in pure  Python. For machine learning applications you should instead use the `tf.data.Dataset` interface (see `2_keras.ipynb`). This has the advantage that the underlying file reading and protobuf parsing operations can be translated into TensorFLow Ops and implemented efficiently without passing the data through the Python kernel.\n", "\n"]}, {"metadata": {"id": "KvAUIAn6d5ow", "colab_type": "code", "outputId": "581fdc6a-2f47-4ae3-c0cc-a1aaf2907063", "executionInfo": {"status": "ok", "timestamp": 1548458130038, "user_tz": 480, "elapsed": 532214, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "cell_type": "code", "source": ["# Check out the features. They should correspond to what we generated in\n", "# make_example_img() above.\n", "example = tf.train.Example()\n", "example.ParseFromString(record)\n", "print(list(example.features.feature.keys()))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "BDGmgNQ7dgOz", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Extract the label and the image data from the example protobuf.\n", "# (use above section \"tf.train.Example\" for reference).\n", "label_int =\n", "img_64 = \n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "3e0Dwc09efDD", "colab_type": "code", "outputId": "ccc8824a-cf8f-427a-f224-f1df02da3399", "executionInfo": {"status": "ok", "timestamp": 1548458130631, "user_tz": 480, "elapsed": 532799, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 372}}, "cell_type": "code", "source": ["# Visualize the image:\n", "print(labels[label_int])\n", "pyplot.matshow(np.array(img_64).reshape((64, 64)));"], "execution_count": null, "outputs": []}, {"metadata": {"id": "YhfIKXXChrab", "colab_type": "code", "outputId": "88e65e82-0d22-4c48-a436-7ec3f9d43007", "executionInfo": {"status": "ok", "timestamp": 1548458131254, "user_tz": 480, "elapsed": 533417, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 384}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Check that we have an equal distribution of labels in the training files.\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "lI01xshyjTbH", "colab_type": "text"}, "cell_type": "markdown", "source": ["## More on protobufs"]}, {"metadata": {"id": "aGej8L70W7AH", "colab_type": "code", "outputId": "3dc92983-0a39-4ae9-b0fd-0b31b64be61b", "executionInfo": {"status": "ok", "timestamp": 1548458137802, "user_tz": 480, "elapsed": 539958, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 136}}, "cell_type": "code", "source": ["# If we want to create our own protocol buffers, we first need to install\n", "# some programs...\n", "!apt-get -y install protobuf-compiler python-pil python-lxml"], "execution_count": null, "outputs": []}, {"metadata": {"id": "lkF7qlk3XwA2", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Step 1 : Write a proto file that describes our data format.\n", "# YOUR ACTION REQUIRED: Complete the definition of the \"Person\" message (you\n", "# can use the slide for inspiration).\n", "with open('person.proto', 'w') as f:\n", "  f.write('''\n", "      syntax = \"proto2\";\n", "  ''')\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "pBAJaBXBXwrH", "colab_type": "code", "outputId": "0933f05b-d8fd-4f9d-910e-995b290ec366", "executionInfo": {"status": "ok", "timestamp": 1548458141576, "user_tz": 480, "elapsed": 543721, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 102}}, "cell_type": "code", "source": ["# Step 2 : Compile proto definition to a Python file.\n", "!protoc --python_out=. person.proto\n", "!ls -lh"], "execution_count": null, "outputs": []}, {"metadata": {"id": "2T9fzSImX_M1", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Step 3 : Import code from generated Python file.\n", "from person_pb2 import Person"], "execution_count": null, "outputs": []}, {"metadata": {"id": "gvOO-6qxX_8E", "colab_type": "code", "outputId": "a739dd6d-30ab-4cf6-f6e8-5523107f1149", "executionInfo": {"status": "ok", "timestamp": 1548458141579, "user_tz": 480, "elapsed": 543713, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "cell_type": "code", "source": ["person = Person()\n", "person.name = 'John Doe'\n", "person.email = 'john.doe@gmail.com'\n", "person.lucky_numbers.extend([13, 99])\n", "person.SerializeToString()"], "execution_count": null, "outputs": []}, {"metadata": {"id": "jyrH9BxLZsrf", "colab_type": "code", "outputId": "7b8c6e33-902b-47f6-e70b-6a500b98ce60", "executionInfo": {"status": "ok", "timestamp": 1548458141579, "user_tz": 480, "elapsed": 543707, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/-eofaMMIfen4/AAAAAAAAAAI/AAAAAAAAABE/dzY58NhFiBE/s64/photo.jpg", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 51}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Compare the size of the serialized person structure in proto format\n", "# vs. JSON encoded (you can use Python's json.dumps() and list members\n", "# manually, or import google.protobuf.json_format).\n", "\n", "# Which format is more efficient? Why?\n", "# Which format is easier to use?\n", "# Which format is more versatile?\n"], "execution_count": null, "outputs": []}]}