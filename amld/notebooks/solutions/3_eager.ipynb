{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"name": "3_eager", "version": "0.3.2", "provenance": [], "collapsed_sections": [], "toc_visible": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "accelerator": "GPU"}, "cells": [{"metadata": {"id": "nOLvC15Xfl_M", "colab_type": "text"}, "cell_type": "markdown", "source": ["# TensorFlow Eager\n", "\n", "Let's take a closer look at the TensorFlow API as well as TensorFlow's  [eager execution](https://www.tensorflow.org/guide/eager).\n", "\n", "The traditional approach of doing computations with TensorFlow requires to build a dataflow graph that can be evaulated in the context of a session (more at [TF guide - Graphs and Sessions](https://www.tensorflow.org/guide/graphs)). However, this way of splitting the computation into a \"graph construction phase\" and a \"execution phase\" is unintuitive and especially frustrating for beginners.\n", "\n", "In this Colab wel'll leave out graphs and sessions altogether and only use TensorFlow's eager execution mode. Overall, some of its key advantages are:\n", "\n", "1.   It's not necessary to build a graph and evaluate it inside sessions before obtaining results.\n", "2.   Reduced boilerplate code.\n", "3. Easier debugging as results and run-time errors are returned immediately.\n", "\n"]}, {"metadata": {"id": "bhn7C_aX1Q-6", "colab_type": "code", "outputId": "38e75db5-a293-408b-f1fc-662447109de4", "executionInfo": {"status": "ok", "timestamp": 1548521758641, "user_tz": -60, "elapsed": 944, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["import json, os\n", "import numpy as np\n", "from matplotlib import pyplot as plt\n", "import tensorflow as tf\n", "\n", "# As of TensorFlow 1.12, Eager mode still needs to be activated explicitly.\n", "# Expect this to change with TensorFlow 2.0\n", "tf.enable_eager_execution()\n", "\n", "# version, GPU?, TPU?\n", "tf.__version__, tf.test.is_gpu_available() and tf.test.is_built_with_cuda(), 'COLAB_TPU_ADDR' in os.environ"], "execution_count": null, "outputs": []}, {"metadata": {"id": "UwtuKp3z-eqE", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["## Load data from Drive (Colab only).\n", "data_path = '/content/gdrive/My Drive/amld_data/zoo_img'\n", "## ... or load data from local machine.\n", "# data_path = './amld_data'\n", "## ... or use a prepared dataset from Cloud (Colab only).\n", "#data_path = 'gs://amld-datasets/zoo_img_50k'"], "execution_count": null, "outputs": []}, {"metadata": {"id": "itNiEr6rUXYa", "colab_type": "code", "outputId": "27cbf5f9-1309-49e1-b568-21d832836e77", "executionInfo": {"status": "ok", "timestamp": 1548521764522, "user_tz": -60, "elapsed": 6784, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 629}}, "cell_type": "code", "source": ["# (Copied from ./2_keras.ipynb)\n", "if data_path.startswith('/content/gdrive/'):\n", "  from google.colab import drive\n", "  drive.mount('/content/gdrive')\n", "if data_path.startswith('gs://'):\n", "  from google.colab import auth\n", "  auth.authenticate_user()\n", "  !gsutil ls -lh \"$data_path\"\n", "else:\n", "  !ls -lh \"$data_path\""], "execution_count": null, "outputs": []}, {"metadata": {"id": "_6RrqVkp4LSH", "colab_type": "text"}, "cell_type": "markdown", "source": ["## Tensors\n", "\n", "A Tensor in TF is a generalized format that can describe a scalar, vector, matrix or higher dimensional data (also see\n", " [TF guide - Tensors](https://www.tensorflow.org/guide/tensors)) and is the most essential data type in TF.  The essential Tensor types include:\n", "*  `tf.constant`\n", "*  `tf.Variable`\n", "*  `tf.SparseTensor`\n", "*  `tf.placeholder` - not supported when using TF with eager execution\n", "\n", "The essential Tensor attributes are:\n", "\n", "*   Rank - number of dimensions\n", "*   Shape - number of elements in each dimension\n", "* Data type - for example `tf.float32`: **must be the same for every dimension**\n", "\n", "Let's look at the different Tensor types."]}, {"metadata": {"id": "Cpqcn--jyLq3", "colab_type": "text"}, "cell_type": "markdown", "source": ["** tf.constant ** - A basic immutable Tensor\n", "\n", "We can define a constant tensor with a dimension of 12x1."]}, {"metadata": {"id": "M5xfkuTk1ent", "colab_type": "code", "outputId": "ae843f4f-9a72-4b3c-8e67-8d2cfdb7c708", "executionInfo": {"status": "ok", "timestamp": 1548521764523, "user_tz": -60, "elapsed": 6767, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 71}}, "cell_type": "code", "source": ["tensor12 = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n", "print(tensor12, \"\\nFirst element:\\n\\t\", tensor12[0])"], "execution_count": null, "outputs": []}, {"metadata": {"id": "KV13j5Iexc9q", "colab_type": "text"}, "cell_type": "markdown", "source": ["As can be seen, all components are Tensors themselves, too. This kind of repesentation is useful for example for training data and label where we might want to ensure that no modifications of the source data are possible."]}, {"metadata": {"id": "9r33ZdQY_Y8u", "colab_type": "text"}, "cell_type": "markdown", "source": ["** tf.Variable ** - A mutable Tensor\n", "\n", "If we need Tensors that act like variables for instance for tracking a loss we can use `tf.Variable`.\n", "\n", "Two options to do so are:"]}, {"metadata": {"id": "kTbpmcJsAdE9", "colab_type": "code", "outputId": "6c33f99b-e5af-455c-c5ed-d27346c1d7d3", "executionInfo": {"status": "ok", "timestamp": 1548521764525, "user_tz": -60, "elapsed": 6755, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["# Define a Variable with a known initial value.\n", "loss = tf.Variable(0.01, dtype=float, name=\"loss\")\n", "loss"], "execution_count": null, "outputs": []}, {"metadata": {"id": "2322DTRX8lRm", "colab_type": "code", "outputId": "2c763429-1592-4910-a5f0-a9589ab5bffb", "executionInfo": {"status": "ok", "timestamp": 1548521764526, "user_tz": -60, "elapsed": 6744, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["# Define a variable and only later assign a concrete value.\n", "new_var = tf.get_variable(\"new_var\", shape=(), dtype=tf.int32)\n", "new_var"], "execution_count": null, "outputs": []}, {"metadata": {"id": "cPF3EOj9An9X", "colab_type": "text"}, "cell_type": "markdown", "source": ["For updates, we can then make use of the `assign` operations TF provides.\n", "\n", "Particularly, we can use operations like `.assign`, `.assign_add` and `.assign_sub`."]}, {"metadata": {"id": "SN96XoqtDR_d", "colab_type": "code", "outputId": "b7a483dc-775b-464e-b669-83cf10cafbfb", "executionInfo": {"status": "ok", "timestamp": 1548521764526, "user_tz": -60, "elapsed": 6724, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 53}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Assign the value 1531 to `new_var` and then use `.assign_sub` to subtract 194.\n", "new_var.\n", "new_var.\n", "print('Variable:', new_var)\n", "print('Variable value: ', new_var.value())"], "execution_count": null, "outputs": []}, {"metadata": {"id": "YUM64n-oEv6L", "colab_type": "text"}, "cell_type": "markdown", "source": ["** tf.SparseTensor ** - A sparse representation Tensor\n", "\n", "For sparse Tensors, a more efficient representation is `tf.SparseTensor`."]}, {"metadata": {"id": "0hOin0LxFDan", "colab_type": "code", "outputId": "10733231-9b47-4913-d703-d8b328ef50ef", "executionInfo": {"status": "ok", "timestamp": 1548521764527, "user_tz": -60, "elapsed": 6710, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Address the mistakes in the following assignment to define a\n", "# 3x3 matrix with ones on the \\ diagonal and zeros everywhere else. \n", "# Hint: You might want to press <TAB> inside the () to get more information.\n", "sparse_matrix = tf.SparseTensor()\n", "sparse_matrix.values"], "execution_count": null, "outputs": []}, {"metadata": {"id": "J_fYLKh3FBje", "colab_type": "text"}, "cell_type": "markdown", "source": ["Of course, you can also create a diagonal TF matrix in simpler ways by exploring the TF API more."]}, {"metadata": {"id": "Rt7UvXcaHb_g", "colab_type": "code", "outputId": "13b7e2b0-2628-4876-fe3a-14a6410572fd", "executionInfo": {"status": "ok", "timestamp": 1548521764527, "user_tz": -60, "elapsed": 6694, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 161}}, "cell_type": "code", "source": ["a=tf.diag([1,1,1])\n", "b=tf.eye(3)\n", "a, b"], "execution_count": null, "outputs": []}, {"metadata": {"id": "_7URJpig4WLF", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Operator overloading & Broadcasting"]}, {"metadata": {"id": "hQXNdqiVHjWo", "colab_type": "text"}, "cell_type": "markdown", "source": ["In general, operator overloading allows to define custom behavior for basic operators like: -, +, / and *. The result might depend on the arguments':\n", "* Order\n", "* Data type\n", "* Content\n", "\n", "TensorFlow makes use of operator overloading to simplify the core API as we will see below.\n", "\n", "In addition, it makes use of something called Broadcasting.\n", "\n", "> \"Broadcasting is the process of making arrays with different shapes have compatible shapes for arithmetic operations. The terminology is borrowed from [Numpy broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\" - see https://www.tensorflow.org/xla/broadcasting\n", "\n", "Overall, this allows to succinctly and efficiently operate with tensors of different shapes and types.  "]}, {"metadata": {"id": "h03uPhiE3cqe", "colab_type": "code", "outputId": "7a309cfa-646d-441b-cfe8-0aec10ec72b3", "executionInfo": {"status": "ok", "timestamp": 1548521764527, "user_tz": -60, "elapsed": 6677, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["# Broadcasting + operator overloading : Try to write the line below more succintly...\n", "# YOUR ACTION REQUIRED: Simplify the given statement by making use of TF's\n", "# operator overloading and Broadcasting.\n", "tensor12_plus_1 = tf.add(tensor12, tf.ones(shape=tensor12.shape, dtype=tf.int32))\n", "tensor12_plus_1"], "execution_count": null, "outputs": []}, {"metadata": {"id": "I52dN5v8B5FK", "colab_type": "text"}, "cell_type": "markdown", "source": ["TensorFlow accepts Python numbers or Numpy arrays in most places and converts them to tensors on the fly."]}, {"metadata": {"id": "HRRAemdxCBeB", "colab_type": "code", "outputId": "4198d384-055f-4203-84ef-9b51a96e9127", "executionInfo": {"status": "ok", "timestamp": 1548521764528, "user_tz": -60, "elapsed": 6656, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Try to replace one or both of the arguments with a\n", "# tf.constant() or with a np.array() and see what happens. Use different shapes.\n", "tf.add(1, 2)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "57LGLtjEqUlb", "colab_type": "code", "outputId": "81fec0bd-70f1-46c4-f394-21951303f022", "executionInfo": {"status": "ok", "timestamp": 1548521764528, "user_tz": -60, "elapsed": 6640, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 125}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Use broadcasting to generate an array like this:\n", "# [[11, 12, 13, ...],\n", "#  [21, 22, 23, ...],\n", "#  [31, 32, 33, ...],\n", "#  ...,\n", "# ]\n", "# (Tip: use tf.range() & tf.reshape() or tf.expand_dims())\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "dZnMYsUZRSVP", "colab_type": "text"}, "cell_type": "markdown", "source": ["When applying an operation to Tensors they must be of the same datatype. In any other case, you might see a ValueError like below."]}, {"metadata": {"id": "ShDUlar_0-Nl", "colab_type": "code", "outputId": "cd1a43a5-8d20-4b01-9f7b-e51bb2016055", "executionInfo": {"status": "ok", "timestamp": 1548521764533, "user_tz": -60, "elapsed": 6630, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 71}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED: Try to change the datatype of one of the tensors to fix the ValueError.\n", "multiplier = tf.constant(1.5)\n", "tensor12 * multiplier\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "1Ubegrgt4gAy", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Handling"]}, {"metadata": {"id": "p_Fcd-4YUSVv", "colab_type": "text"}, "cell_type": "markdown", "source": ["Accessing individual elements of a 2D tensor."]}, {"metadata": {"id": "ZhimrP5T1MZc", "colab_type": "code", "outputId": "9d9ba1ac-105a-4a9e-9dcb-1b9c845bd6fe", "executionInfo": {"status": "ok", "timestamp": 1548521764534, "user_tz": -60, "elapsed": 6617, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 143}}, "cell_type": "code", "source": ["# A batch of 3 zero padded 1D tensors.\n", "batch = tf.constant([[1, 2, 3, 0, 0],\n", "                     [2, 4, 6, 8, 0],\n", "                     [3, 6, 0, 0, 0]])\n", "# Note that individual elements have lengths < batch.shape[1]\n", "# but are zero padded.\n", "lengths = tf.constant([3, 4, 2])\n", "\n", "# The FIRST elements can be accessed by using Python's\n", "# overloaded bracket indexing OR the related tf.slice():\n", "print('first elements:')\n", "print(batch[0:3, 0:1].numpy())\n", "# Same as above, calling slice operator explicitly.\n", "print(tf.slice(batch, [0, 0], [3, 1]).numpy())"], "execution_count": null, "outputs": []}, {"metadata": {"id": "YipD-4eHV8Jk", "colab_type": "text"}, "cell_type": "markdown", "source": ["Accessing the LAST (non-padded) element within every sequence is somewhat more involved.\n", "\n", "You need to specify both the indices in the first and the second dimension and then use `tf.gather_nd()`."]}, {"metadata": {"id": "agj5eLJ41RL0", "colab_type": "code", "outputId": "c936d2c6-57ee-4b68-97b8-f77b6e87dc25", "executionInfo": {"status": "ok", "timestamp": 1548521764534, "user_tz": -60, "elapsed": 6609, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 53}}, "cell_type": "code", "source": ["# Accessing the last elements is slightly more involved:\n", "indices_0 = list(range(3))\n", "indices_1 = lengths - 1\n", "print('last elements:')\n", "# -> Go check out the documentation of tf.gather_nd() ...\n", "print(tf.gather_nd(batch, tf.transpose([indices_0, indices_1])))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "ljwNtQiZXWhZ", "colab_type": "text"}, "cell_type": "markdown", "source": ["Below you have an integer tensor and then an expression that is set True for all elements that are odd.\n", "\n", "Try to print those elements using the operations `tf.where()` and `tf.gather()`.\n"]}, {"metadata": {"id": "CAt9oxPD1dZX", "colab_type": "code", "outputId": "70e7c0fd-399a-4238-96b5-0a35ae662ca7", "executionInfo": {"status": "ok", "timestamp": 1548521764535, "user_tz": -60, "elapsed": 6597, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 107}}, "cell_type": "code", "source": ["numbers = tf.range(1, 11)\n", "odd_condition = tf.logical_not(tf.equal(0, tf.mod(numbers, 2)))\n", "\n", "# YOUR ACTION REQUIRED:\n", "# Provide the correct expression for odd_indices and odd_numbers.\n", "# You can use tf.where and tf.gather to this.\n", "odd_indices =\n", "odd_numbers =\n", "odd_numbers.numpy()"], "execution_count": null, "outputs": []}, {"metadata": {"id": "2GGZ-cbI4u48", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Shape manipulation\n", "\n", "The tensor's underlying data might be on a different device. The tensor object is merely a reference to that data."]}, {"metadata": {"id": "AOUlArs5CVaX", "colab_type": "text"}, "cell_type": "markdown", "source": ["** Basic reshaping **\n", "\n", "We can reshape a tensor like `tensor12` into a 2x6 format in the following way."]}, {"metadata": {"id": "oKm8mxl0txLr", "colab_type": "code", "outputId": "70120600-47bd-4f82-b9e5-507401712e26", "executionInfo": {"status": "ok", "timestamp": 1548521764536, "user_tz": -60, "elapsed": 6587, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 71}}, "cell_type": "code", "source": ["tf.reshape(tensor12, [2, 6])"], "execution_count": null, "outputs": []}, {"metadata": {"id": "eo4JoQ6oGMSP", "colab_type": "text"}, "cell_type": "markdown", "source": ["You can access the underlying data as a **numpy** array. Note the change in notation - tensors don't have methods for shape transformation etc, as opposed to numpy arrays."]}, {"metadata": {"id": "6EvEMlDRt1D9", "colab_type": "code", "outputId": "0938ef0b-c092-4a4b-ad0e-f20f872950a8", "executionInfo": {"status": "ok", "timestamp": 1548521764537, "user_tz": -60, "elapsed": 6564, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 53}}, "cell_type": "code", "source": ["tensor12.numpy().reshape([2, 6])"], "execution_count": null, "outputs": []}, {"metadata": {"id": "ttSEnXui2GHA", "colab_type": "code", "outputId": "06fb3457-e4b8-4983-b531-304045f113ac", "executionInfo": {"status": "ok", "timestamp": 1548521764538, "user_tz": -60, "elapsed": 6550, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 71}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Use `.numpy()` to retrieve the underlying data as a numpy array and then use\n", "# numpy's `.reshape()` to change the shape to a **3x4** matrix.\n", "tensor12.\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "cedGQWVNRFze", "colab_type": "text"}, "cell_type": "markdown", "source": ["** `tf.squeeze()` **\n", "\n", "What does `tf.squeeze()` do? Try it out on `tensor12_3` defined below!"]}, {"metadata": {"id": "lkHpJaFN1HED", "colab_type": "code", "outputId": "4532a3da-fb3e-400d-d934-427be0b39606", "executionInfo": {"status": "ok", "timestamp": 1548521764538, "user_tz": -60, "elapsed": 6537, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 53}}, "cell_type": "code", "source": ["tensor12_3 = tf.reshape(tensor12, [3, 2, 2, 1])\n", "tensor12_3.shape # YOUR ACTION REQUIRED: Apply tf.squeeze() and try to understand what's happening.\n"], "execution_count": null, "outputs": []}, {"metadata": {"id": "mE32D1RhZ6R2", "colab_type": "text"}, "cell_type": "markdown", "source": ["## Training a TF model "]}, {"metadata": {"colab_type": "text", "id": "jsw7kYfPZ5bw"}, "cell_type": "markdown", "source": ["**Automatic differentiation with `tf.GradientTape`**\n", "\n", "Many optimization problems require the computation of gradients. For this purpose, TF supports automatic differentiation by using a  \"tape\" to record all operations executed inside the `tf.GradientTape` context.\n", "This log of operations can then be used to compute the gradients with respect to given variables (see [TF Tutorial on Automatic differentiation](https://www.tensorflow.org/tutorials/eager/automatic_differentiation)).\n", "\n", "Let's look at a concrete example for using this."]}, {"metadata": {"id": "75mlg4YO4_UB", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Machinery to backprop gradients"]}, {"metadata": {"id": "P6ZM_iq7EbcV", "colab_type": "text"}, "cell_type": "markdown", "source": ["Let's see how this works in practice. Suppose our goal is to compute the square root of $2$ by utilizing the multiplication operation and the `GradientTape` mechanism.\n", "\n", "$x = \\pm\\sqrt{2} \\Leftrightarrow x^2 = 2$\n", "\n", "Then we define a \"loss\" : a numerical quantity that always gets smaller (decreases monotonically) when we get closer to the correct solution:\n", "\n", "$loss = (x^2 - 2)^2 \\geq 0$\n", "\n", "Finally, we compute the gradient of the loss with resepect to x. This gradient will be positive if increasing x increases the loss, and negative if increasing x decreases the loss. This means that we can decrease the loss (=getting closer to the solution) by taking a *small* step against the gradient.\n", "\n", "Note that step size (\"learning rate\") $\\eta$ matters : If it is too large, we \"overshoot\", if it is too small, then we need to take a lot of steps to get to the correct value. This method is called **gradient descent** and is the corner stone of most modern machine learning.\n", "\n", "$x:= x - \\eta * \\triangledown_x loss$\n", "\n", "Furthermore, we assume an initial guess of $x = 1.5$."]}, {"metadata": {"id": "4gyWUX1k8LSI", "colab_type": "code", "outputId": "2d6a98ac-e815-4749-8b4a-7e16277c1f2c", "executionInfo": {"status": "ok", "timestamp": 1548521765300, "user_tz": -60, "elapsed": 7285, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 706}}, "cell_type": "code", "source": ["# GradientTape computes gradients with respect to variables. So we need to\n", "# define \"x\" as a tf.Variable.\n", "# (Note that gradient computation would return None with dtype=int...)\n", "x = tf.Variable(1.5, dtype=float)\n", "f = lambda x: x * x\n", "x_squared_target = 2.0\n", "\n", "# Keep values of \"x\" and \"loss\" for plotting.\n", "xs = [x.numpy()]\n", "losses = []\n", "for i in range(10):\n", "  with tf.GradientTape() as tape:\n", "    # Compute function value.\n", "    x_squared = f(x)\n", "    # Loss indicates how far off our current guess is.\n", "    # Minimizing loss == finding better value for x.\n", "    loss = (x_squared - x_squared_target) ** 2\n", "  grad = tape.gradient(loss, x)\n", "  x.assign_add(-0.1 * grad)\n", "  xs.append(x.numpy())\n", "  losses.append(loss.numpy())\n", "\n", "plt.figure()\n", "plt.plot(xs, 'r-')\n", "sg = xs[-1]/abs(xs[-1])\n", "plt.plot([0, len(xs) - 1], [sg*np.sqrt(x_squared_target)]*2, 'k--')\n", "plt.figure()\n", "plt.plot(losses)\n", "plt.gca().set_title('x (red) & loss (blue)');\n", "plt.xlabel('#Steps')\n", "plt.ylabel('Loss')\n", "None\n", "\n", "# YOUR ACTION REQUIRED:\n", "# Try changing the initial value and the learning rate and see what happens..."], "execution_count": null, "outputs": []}, {"metadata": {"id": "QQNMrLLHITgE", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Training a linear model"]}, {"metadata": {"id": "-FQfAY1yIHRH", "colab_type": "text"}, "cell_type": "markdown", "source": ["Now let's use gradients to reimplement the linear model from [2_keras.ipynb](https://github.com/tensorflow/workshops/tree/master/extras/amld/notebooks/solutions/2_keras.ipynb)\n", "\n", "1. Specifying the training data and labels.\n", "2. Reading and parsing the stored training data into a TF supported format.\n", "3. Training our linear NN model using SGD and the data provided by the previous step. "]}, {"metadata": {"id": "JaOea4KP5IDe", "colab_type": "text"}, "cell_type": "markdown", "source": ["**1. Specifying the training data and labels.**"]}, {"metadata": {"id": "D9Lqv4f0IUvk", "colab_type": "code", "outputId": "df405161-5658-4b81-cb3c-bbc6969ba2f2", "executionInfo": {"status": "ok", "timestamp": 1548521766827, "user_tz": -60, "elapsed": 8802, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 89}}, "cell_type": "code", "source": ["labels = [label.strip() for label in tf.gfile.GFile('{}/labels.txt'.format(data_path))]\n", "counts = json.load(tf.gfile.GFile('{}/counts.json'.format(data_path)))\n", "print(\"Labels({:d}):\\n\\t{}\".format(len(labels), labels))\n", "print(\"Counts:\\n\\t{}\".format(counts))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "zDKSey387ZUj", "colab_type": "text"}, "cell_type": "markdown", "source": ["**2. Reading and parsing the stored data into a TF supported format.**"]}, {"metadata": {"id": "3jnHZS8L6hKQ", "colab_type": "code", "outputId": "88944e69-115a-4b97-ed9b-2e8b3ebc7cd3", "executionInfo": {"status": "ok", "timestamp": 1548521767495, "user_tz": -60, "elapsed": 9458, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 53}}, "cell_type": "code", "source": ["# (copied from ./2_keras.ipynb -- see there for comments)\n", "\n", "feature_spec = {\n", "    'label': tf.FixedLenFeature(shape=[1], dtype=tf.int64),\n", "    'img_64': tf.FixedLenFeature(shape=[64, 64], dtype=tf.int64),\n", "}\n", "\n", "def parse_example(serialized_example):\n", "    features = tf.parse_single_example(serialized_example, feature_spec)\n", "    label = features.pop('label')\n", "    features['img_64'] = tf.cast(features['img_64'], tf.float32) / 255.\n", "    return features['img_64'], tf.one_hot(tf.squeeze(label), len(labels))\n", "\n", "batch_size = 100\n", "steps_per_epoch = counts['train'] // batch_size\n", "dataset = tf.data.TFRecordDataset(tf.gfile.Glob('{}/train-*'.format(data_path)))\n", "dataset = dataset.map(parse_example)\n", "dataset = dataset.batch(batch_size).repeat()\n", "\n", "# Read a single batch and print tensor dimensions.\n", "for x, y in dataset:\n", "  break\n", "x.shape, y.shape"], "execution_count": null, "outputs": []}, {"metadata": {"id": "XiXOBykV7-fL", "colab_type": "text"}, "cell_type": "markdown", "source": ["** Defining the weights and biases. **\n", "\n", "The linear model is defined by the follwoing computation:\n", "\n", "$$y = Wx + b$$\n", "\n", "With\n", "- $y$ : Probabilities of the output classes (should approach the one-hot encoded labels).\n", "- $x$ : The input (pixel intensities).\n", "- $W$, $b$ : model parameters to be learnt via gradient descent."]}, {"metadata": {"id": "lUH4EyKlQbM_", "colab_type": "code", "outputId": "ba6af239-197d-4bca-a219-413deda297a8", "executionInfo": {"status": "ok", "timestamp": 1548521767496, "user_tz": -60, "elapsed": 9447, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 35}}, "cell_type": "code", "source": ["# Define the variables with the correct dimensions.\n", "W = tf.Variable(tf.random_normal(shape=(x.shape[1] * x.shape[2], y.shape[1])))\n", "b = tf.Variable(tf.random_normal(shape=(y.shape[1], )))\n", "W.shape, b.shape"], "execution_count": null, "outputs": []}, {"metadata": {"id": "vu0kZiUB8SRE", "colab_type": "text"}, "cell_type": "markdown", "source": ["**3. Training our linear NN model using SGD and the data provided by the previous step.**"]}, {"metadata": {"id": "QDkUTG9ZV-nt", "colab_type": "code", "outputId": "43a4f792-5913-43c9-bf25-b651e40d06f2", "executionInfo": {"status": "ok", "timestamp": 1548521791938, "user_tz": -60, "elapsed": 33878, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "collapsed": true, "colab": {"base_uri": "https://localhost:8080/", "height": 179}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Adjust the training below to use a decaying learning rate / step size instead\n", "# of using a fixed rate of 0.01.\n", "# (Using a decaying learning rate is often a good idea to make quick progress in\n", "#  the beginning but avoid making too big changes to already tuned parameters.)\n", "\n", "\n\n", "\n", "# Record values for loss and accuracy for plotting purposes.\n", "losses = []\n", "accs = []\n", "# Train for two epochs.\n", "epochs = 2\n", "for step, (x, y) in enumerate(dataset):\n", "  if step >= epochs * steps_per_epoch:\n", "    break\n", "  # Compute predictions from input and weights.\n", "  with tf.GradientTape() as tape:\n", "    logits = tf.matmul(tf.reshape(x, (x.shape[0], -1)), W) + b\n", "    loss = tf.losses.softmax_cross_entropy(y, logits)\n", "  losses.append(loss.numpy())\n", "  W_grad, b_grad = tape.gradient(loss, (W, b))\n", "\n", "  # Gradient descent.\n", "  W.assign_add(-0.01 * W_grad)\n", "  b.assign_add(-0.01 * b_grad)\n", "\n", "  # Compute accuracy.\n", "  good_preds = tf.equal(tf.argmax(logits, axis=1), tf.argmax(y, axis=1))\n", "  acc = tf.reduce_mean(tf.cast(good_preds, tf.float32))\n", "  accs.append(acc.numpy())\n", "  # Prove we didn't freeze...\n", "  if step and step % 100 == 0:\n", "    print('step={:4d} loss={:2.3f} acc={:.3f}'.format(\n", "        step, np.mean(losses[-100:]), np.mean(accs[-100:])))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "xRudDUpqx4dK", "colab_type": "code", "outputId": "32dbd4c2-cb0d-4ce9-d429-6d8e095daf1e", "executionInfo": {"status": "ok", "timestamp": 1548521792320, "user_tz": -60, "elapsed": 34245, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 347}}, "cell_type": "code", "source": ["# Plot accuracy (should go up) and loss (should go down).\n", "# Note large variance from one batch to another.\n", "plt.plot(accs, 'g', label='accuracy')\n", "plt.legend(loc='upper right')\n", "plt.grid(False)\n", "plt.twinx().plot(losses, 'r', label='loss')\n", "plt.legend(loc='lower right')\n", "plt.grid(False)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "w-ELRwea7Qvl", "colab_type": "text"}, "cell_type": "markdown", "source": ["## Keras, revisited"]}, {"metadata": {"id": "04N8lmIZaYsk", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Models with custom layers\n", "\n", "In addition to using Keras in the simplified way as we've seen in `2_keras`,\n", "we can also customize specific layers.\n", "\n", "You might want to take a short look at: [TF guide - Keras Custom Layers](https://www.tensorflow.org/guide/keras#custom_layers)\n", "\n", "Particulary, this requires us to implement a class inheriting from `tf.keras.layers.Layer` and implementing the methods:\n", "\n", "1.   `build`\n", "2.   `call`\n", "3.   `compute_output_shape`\n", "4. (optional) `get_config` and `from_config` for layer serialization support"]}, {"metadata": {"id": "JtAE88pF7SH6", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["class MyLinearLayer(tf.keras.layers.Layer):\n", "\n", "  def __init__(self, output_dim, **kwargs):\n", "    self.output_dim = output_dim\n", "    super(MyLinearLayer, self).__init__(**kwargs)\n", "\n", "  # Define variables using \"self.add_weight()\" so Keras knows how to update weights.\n", "  def build(self, input_shape):\n", "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n", "    self.W = self.add_weight(name='W',\n", "                             shape=shape,\n", "                             initializer='normal',\n", "                             trainable=True)\n", "    self.b = self.add_weight(name='b',\n", "                             shape=shape[1:],\n", "                             initializer='normal',\n", "                             trainable=True)\n", "    super(MyLinearLayer, self).build(input_shape)\n", "\n", "  # Compute outputs from inputs (forward pass).\n", "  def call(self, inputs):\n", "    logits = tf.matmul(inputs, self.W) + self.b\n", "    return tf.nn.softmax(logits)\n", "\n", "  # Tell Keras how to verify shape conformity of layer stacking.\n", "  def compute_output_shape(self, input_shape):\n", "    shape = tf.TensorShape(input_shape).as_list()\n", "    shape[-1] = self.output_dim\n", "    return tf.TensorShape(shape)\n", "  \n", "  # Make layer work with model.get_config() and model.from_config().\n", "  def get_config(self):\n", "    base_config = super(MyLinearLayer, self).get_config()\n", "    base_config['output_dim'] = self.output_dim\n", "    return base_config\n", "  \n", "  @classmethod\n", "  def from_config(cls, config):\n", "    return cls(**config)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "PmV7vx6deSSS", "colab_type": "text"}, "cell_type": "markdown", "source": ["**Model definition**\n", "\n", "We can now define our TF model using `tf.keras.Sequential`."]}, {"metadata": {"id": "mYSJOtfAnfeu", "colab_type": "code", "outputId": "44764a72-f475-4d03-ef05-fcedbd0d122f", "executionInfo": {"status": "ok", "timestamp": 1548521792324, "user_tz": -60, "elapsed": 34214, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 215}}, "cell_type": "code", "source": ["model = tf.keras.Sequential()\n", "model.add(tf.keras.layers.Flatten(input_shape=(64, 64,)))\n", "model.add(MyLinearLayer(len(labels)))\n", "\n", "model.compile(\n", "    optimizer=tf.train.AdamOptimizer(),\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy'])\n", "\n", "model.summary()"], "execution_count": null, "outputs": []}, {"metadata": {"id": "XLi4Kn1yedB2", "colab_type": "text"}, "cell_type": "markdown", "source": ["**Training the model**"]}, {"metadata": {"id": "290Aujx7n6pp", "colab_type": "code", "outputId": "e871b837-1e98-41cf-9299-3291deef1204", "executionInfo": {"status": "ok", "timestamp": 1548521805412, "user_tz": -60, "elapsed": 47286, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 71}}, "cell_type": "code", "source": ["model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=1)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "4et6U9VveluP", "colab_type": "text"}, "cell_type": "markdown", "source": ["**Saving and loading a (trained) model**"]}, {"metadata": {"id": "GUOoeyIV6a2a", "colab_type": "code", "outputId": "3ee9a33a-800a-48ec-93a8-f4f5005ee6fc", "executionInfo": {"status": "ok", "timestamp": 1548521805652, "user_tz": -60, "elapsed": 47509, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 73}}, "cell_type": "code", "source": ["# Note that the Keras serialized model contains weights and model parameters,\n", "# but not the Python code for creating the layers!\n", "# If you save a model with a custom layer then you need to define the layer and\n", "# provide it to .load_model() as an argument so the model can be instantiated:\n", "model.save('./tmp.h5')\n", "loaded_model = tf.keras.models.load_model('./tmp.h5', dict(MyLinearLayer=MyLinearLayer))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "ZSf4HKPUfrrT", "colab_type": "text"}, "cell_type": "markdown", "source": ["### Training a bidirectional LSTM\n", "\n", "Instead of using the images directly, we can also utilize the stroke data in connection with a recurrent neural network.\n", "\n", "Particularly, we will train a bidrectional LSTM by going through the following steps:\n", "\n", "1. Data preparation\n", "2. Data inspection\n", "3. Model definition\n", "4. Model training"]}, {"metadata": {"id": "SVXDO_1v5cgN", "colab_type": "text"}, "cell_type": "markdown", "source": ["**1. Data preparation**\n", "\n", "The stroke data is available inside `TFRecord` files. Let's inspect the features\n", "of one example first."]}, {"metadata": {"id": "tq_sI9b5RQnT", "colab_type": "code", "outputId": "bbf122c3-e7b0-4ef3-8361-a2a3c2c263df", "executionInfo": {"status": "ok", "timestamp": 1548521824521, "user_tz": -60, "elapsed": 1463, "user": {"displayName": "Ruslan Habalov", "photoUrl": "https://lh3.googleusercontent.com/-pWs_Eo0vtgo/AAAAAAAAAAI/AAAAAAAABGE/gIVAmjCxY-4/s64/photo.jpg", "userId": "12657326958022596984"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 89}}, "cell_type": "code", "source": ["data_path_stroke = data_path.replace('_img', '_stroke')\n", "tf_records_file = tf.gfile.Glob('{}/train-*'.format(data_path_stroke))[0]\n", "print(\"One TFRecords file:\\n\\t{}\".format(tf_records_file))\n", "for record in tf.io.tf_record_iterator(tf.gfile.Glob('{}/train-*'.format(data_path_stroke))[0]):\n", "  first_example = tf.train.Example.FromString(record)\n", "  break\n", "print(\"Features in example:\\n\\t{}\".format(' '.join(first_example.features.feature.keys())))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "hvyWkIGahwW-", "colab_type": "text"}, "cell_type": "markdown", "source": ["Our recurrent neural network will expect dense tensors with fixed lengths. However, the different examples can have variable stroke lengths.\n", "\n", "**Note**: The QuickDraw stroke coordinate \"sparse tensors\" have a single dimension and do not contain any zeros at all.\n", "\n", "Let's define a helper function that:\n", "\n", "1.   Limits variable length sparse tensors to a maximum length.\n", "2.   Converts them to dense tensors."]}, {"metadata": {"id": "RwjrgscDeagd", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["def convert_sparse(sparse, max_len):\n", "  \"\"\"Converts batched sparse tensor to dense tensor with specified size.\n", "\n", "  Args:\n", "    sparse: tf.SparseTensor instance of shape=[n].\n", "    max_len: Truncates / zero-pads the dense tensor the specified max_len.\n", "  \"\"\"\n", "  # Convert to dense tensor.\n", "  dense = tf.sparse.to_dense(sparse)\n", "  # Discard values above max_len.\n", "  dense = dense[:max_len]\n", "  # Zero-pad if length < max_len.\n", "  dense = tf.pad(dense, [[0, max_len - tf.shape(dense)[0]]])\n", "  return dense"], "execution_count": null, "outputs": []}, {"metadata": {"id": "W_mDsULDh81V", "colab_type": "text"}, "cell_type": "markdown", "source": ["Let's look at an example to see how `convert_sparse()` works.\n", "\n", "We will use `stroke_x` as an example `tf.SparseTensor` with the X-coordinates `[1,2,3,4,5]`."]}, {"metadata": {"id": "3HfxkupMem9O", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["stroke_x = tf.SparseTensor(\n", "    indices=[[0], [1], [2], [3], [4]],\n", "    values=[1, 2, 3, 4, 5],\n", "    dense_shape=[5])\n", "# Extract both shorter and longer dense tensors.\n", "dense_short = convert_sparse(stroke_x, max_len=3)\n", "dense_long = convert_sparse(stroke_x, max_len=10)\n", "print(\"Dense short (max_len=3):\\n\\t{}\".format(dense_short.numpy()))\n", "print(\"Dense long (max_len=10):\\n\\t{}\".format(dense_long.numpy()))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "xihq2FQ6YqCG", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["labels_stroke = [label.strip() for label in tf.gfile.GFile('{}/labels.txt'.format(data_path_stroke))]\n", "counts_stroke = json.load(tf.gfile.GFile('{}/counts.json'.format(data_path_stroke)))\n", "print(\"Labels({:d}):\\n\\t{}\".format(len(labels_stroke), labels_stroke))\n", "print(\"Counts:\\n\\t{}\".format(counts_stroke))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "UC_5lflMfr1L", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Maximum number of points in concatenated strokes (known beforehand).\n", "MAX_LEN = 256\n", "\n", "# Because every drawing has a different number of points, we use \"VarLenFeature\"\n", "# and not \"FixedLenFeature\" for the stroke data. This will create a\n", "# \"SparseTensor\".\n", "feature_spec_stroke = {\n", "    'stroke_x': tf.VarLenFeature(dtype=tf.float32),\n", "    'stroke_y': tf.VarLenFeature(dtype=tf.float32),\n", "    'stroke_z': tf.VarLenFeature(dtype=tf.float32),\n", "    'stroke_len': tf.FixedLenFeature([], tf.int64),\n", "    'label': tf.FixedLenFeature([], tf.int64),\n", "}\n", "\n", "def parse_example_stroke(serialized_example):\n", "  \"\"\"Parses a given tf.Example and creates a dense (limited) length tensor.\n", "\n", "  Args:\n", "    serialized_example: tf.Example to parse.\n", "  \"\"\"\n", "  features = tf.parse_single_example(serialized_example, feature_spec_stroke)\n", "  label = features.pop('label')\n", "\n", "  # We create a 'stroke' tensor with shape [3, MAX_LEN] where the first\n", "  # dimension indicates whether the values are X, Y, or Z coordinates.\n", "  stroke = tf.stack([\n", "      convert_sparse(features['stroke_x'], max_len=MAX_LEN),\n", "      convert_sparse(features['stroke_y'], max_len=MAX_LEN),\n", "      convert_sparse(features['stroke_z'], max_len=MAX_LEN),\n", "  ])\n", "  stroke = tf.transpose(stroke, perm=[1, 0])\n", "\n", "  # Also truncate the \"stroke_len\" to MAX_LEN if needed.\n", "  stroke_len = tf.minimum(tf.cast(MAX_LEN, tf.int64), features['stroke_len'])\n", "\n", "  return stroke, tf.one_hot(label, depth=len(labels_stroke))\n", "\n", "def make_ds_stroke(files_pattern, batch_size=100):\n", "  \"\"\"Converts all data within multiple TFRecord files into a\n", "     dense (limited) length tensor format, shuffles them and creates batches.\n", "\n", "  Args:\n", "    files_pattern: Path with the format `[...]/train-*`.\n", "    batch_size: Size to use for generating batches. \n", "  \"\"\"\n", "  dataset = tf.data.TFRecordDataset(tf.gfile.Glob(files_pattern))\n", "  dataset = dataset.map(parse_example_stroke).batch(batch_size)\n", "  dataset = dataset.shuffle(buffer_size=5*batch_size).repeat()\n", "  return dataset"], "execution_count": null, "outputs": []}, {"metadata": {"id": "SmwQ9m4kBA8a", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["batch_size = 100\n", "steps_per_epoch = counts_stroke['train'] // batch_size\n", "ds_stroke = make_ds_stroke('{}/train-*'.format(data_path_stroke), batch_size)\n", "ds_stroke_test = make_ds_stroke('{}/test-*'.format(data_path_stroke), batch_size)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "OgGy2F9z5ok9", "colab_type": "text"}, "cell_type": "markdown", "source": ["**2. Data inspection**\n", "\n", "We can now use Matplotlib to visualize the stroke data."]}, {"metadata": {"id": "PnjzYcWMdMLd", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# From ./1_data.ipynb\n", "\n", "from matplotlib import pyplot as plt\n", "\n", "def show_stroke_img(stroke, label, ax=None):\n", "  \"\"\"Plots stroke data.\n", "\n", "  Args:\n", "    stroke: Array of shape=[3, n] where the second dimension\n", "        is time and the first dimension indicates X/Y coordinates\n", "        and Z-dimension that is set to 1 when a stroke ends and\n", "        0 otherwise (the array actually represents an array of\n", "        concatenated strokes and the Z-dimension is needed to tell\n", "        the individual strokes apart).\n", "  \"\"\"\n", "  ax = ax if ax else plt.gca()\n", "  xy = stroke[:2, :].cumsum(axis=1)\n", "  ax.plot(xy[0, :], -xy[1, :])\n", "  # Plot all the strokes, including connecting line between strokes.\n", "  pxy = xy[:, stroke[2] != 0]\n", "  # Red dots mark end of individual strokes.\n", "  ax.plot(pxy[0], -pxy[1], 'ro')\n", "  ax.set_xticks([])\n", "  ax.set_yticks([])\n", "  ax.set_title(label)\n", "\n", "# Load a single batch of images:\n", "for x, y in ds_stroke:\n", "  break\n", "\n", "# Plot some images\n", "plt.figure(figsize=(10, 2))\n", "for i in range(5):\n", "  ax = plt.subplot(1, 5, i+1)\n", "  show_stroke_img(x[i].numpy().T, labels_stroke[y[i].numpy().argmax()], ax)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "CPjiA4Ne59j8", "colab_type": "text"}, "cell_type": "markdown", "source": ["**3. Model definition**\n", "\n", "While defining a linear model using basic TensorFlow operations was quite easy, defining a bidirectional LSTM would be a nightmare!\n", "\n", "Luckily Keras provides us with good implementations of many common network components and putting these together requires only a few lines of code:"]}, {"metadata": {"id": "AN22HwgRqcrs", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["lstm_model = tf.keras.Sequential()\n", "\n", "if tf.test.is_gpu_available():\n", "  # CuDNNLSTM doesn't support masking.\n", "  lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNLSTM(units=256), input_shape=(MAX_LEN, 3)))\n", "else:\n", "  # Masking means that we don't do computations on all the \"0\" used for padding\n", "  # of sequences shorter than MAX_LEN.\n", "  # While masking is not strictly needed it makes learning a lot faster.\n", "  lstm_model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(MAX_LEN, 3)))\n", "  lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256), input_shape=(MAX_LEN, 3)))\n", "\n", "lstm_model.add(tf.keras.layers.Dense(len(labels_stroke), activation='softmax'))\n", "\n", "lstm_model.compile(\n", "    optimizer=tf.train.AdamOptimizer(0.01),\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy', tf.keras.metrics.categorical_accuracy])\n", "\n", "lstm_model.summary()"], "execution_count": null, "outputs": []}, {"metadata": {"id": "YkW7lhU86BdH", "colab_type": "text"}, "cell_type": "markdown", "source": ["**4. Training the model**\n"]}, {"metadata": {"id": "AYSQDHIyaNMG", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# This is a pretty heavy model. If you train on CPU you probably want to reduce\n", "# the number of steps...\n", "lstm_model.fit(ds_stroke, steps_per_epoch=steps_per_epoch, epochs=1)\n", "lstm_model.evaluate(ds_stroke_test, steps=10)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "grr29b3-gCd-", "colab_type": "text"}, "cell_type": "markdown", "source": ["# ----- Optional part -----"]}, {"metadata": {"id": "yIUGFX2puKkT", "colab_type": "text"}, "cell_type": "markdown", "source": ["## TensorBoard\n", "\n", "TensorBoard is a great tool to observe variables during training (especially useful)"]}, {"metadata": {"id": "ksy0-ftJflXV", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# You can also run this section multiple times specifying different values for\n", "# \"tensorboard_path\" -- TensorBoard allows you to compare the different runs.\n", "tensorboard_path = './tensorboard/lstm1'\n", "!rm -rf $tensorboard_path\n", "os.makedirs(tensorboard_path, exist_ok=True)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "9cbs06JH-AHO", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# This callback will make Keras record loss and metrics.\n", "callbacks = [\n", "    tf.keras.callbacks.TensorBoard(log_dir=tensorboard_path),\n", "]"], "execution_count": null, "outputs": []}, {"metadata": {"id": "AtQK94qsJgLC", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# \"strokes\" has shape [?, MAX_LEN, 3] and was converted from a sparse tensor.\n", "# Unless the original variable length tensor had a length >= MAX_LEN, the tensor\n", "# will be filled with zeroes at indices [?, stroke_length:, :] - this function\n", "# returns the actual stroke lengths for a batch of padded strokes.\n", "def get_stroke_lengths(strokes):\n", "  batch_size, max_length = strokes.shape.as_list()[:2]\n", "  nonzero = tf.greater(tf.reduce_sum(tf.cast(tf.greater(strokes, 0), tf.float32), axis=2), 0)\n", "  return max_length - tf.argmax(tf.cast(nonzero, tf.float32)[:,::-1], axis=1)\n", "\n", "# Illustrate the function's return value with an example:\n", "get_stroke_lengths(tf.constant([[[0.1], [0.2], [0], [0.1], [0], [0]]]))"], "execution_count": null, "outputs": []}, {"metadata": {"id": "vT2ZD4EUEs-2", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Under the hood, Keras will initialize a \"summary writer\" and then use\n", "# tf.contrib.summary.scalar() to record loss/metrics during training.\n", "# The following method will record the stroke_len. For these instrutions to be\n", "# called with the data of every processed batch, we wrap it into a \"Lambda\"\n", "# layer (a Keras layer wrapping a Python function that has no weights).\n", "# Note that usually we would use Lambda layers to perform some computation on\n", "# the input. In this case we \"pass through\" the input, but inspect it and record\n", "# summaries.\n", "\n", "summary_writer = tf.contrib.summary.create_file_writer(\n", "    tensorboard_path, flush_millis=1000)\n", "\n", "def record_stroke_length(strokes):\n", "  # Manually increase the step counter. This will serve as the \"x axis\".\n", "  tf.train.get_or_create_global_step().assign_add(1)\n", "  stroke_lengths = get_stroke_lengths(strokes)\n", "  with summary_writer.as_default():\n", "    with tf.contrib.summary.always_record_summaries():\n", "      # Record the average length at every step:\n", "      tf.contrib.summary.scalar('average_stroke_lengths', tf.reduce_mean(stroke_lengths))\n", "    with tf.contrib.summary.record_summaries_every_n_global_steps(10):\n", "      # Record the length distribution every 10 steps. Check out the\n", "      # visualizations in TensorBoard's \"histogram\" and \"distribution\" tabs!\n", "      tf.contrib.summary.histogram('stroke_lengths', stroke_lengths)\n", "  return strokes"], "execution_count": null, "outputs": []}, {"metadata": {"id": "TYOetgwu1fcG", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Code copied from section \"Training a bidirectional LSTM\", but with an\n", "# additional Lambda layer for the recording fo the stroke lengths:\n", "\n", "lstm_model = tf.keras.Sequential()\n", "\n", "lstm_model.add(tf.keras.layers.Lambda(record_stroke_length, input_shape=(MAX_LEN, 3)))\n", "\n", "if tf.test.is_gpu_available():\n", "  # CuDNNLSTM doesn't support masking.\n", "  lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNLSTM(units=256)))\n", "else:\n", "  # Masking means that we don't do computations on all the \"0\" used for padding\n", "  # of sequences shorter than MAX_LEN.\n", "  # While masking is not strictly needed it makes learning a lot faster.\n", "  lstm_model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(MAX_LEN, 3)))\n", "  lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256)))\n", "\n", "lstm_model.add(tf.keras.layers.Dense(len(labels_stroke), activation='softmax'))\n", "\n", "lstm_model.compile(\n", "    optimizer=tf.train.AdamOptimizer(0.01),\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy', tf.keras.metrics.categorical_accuracy])\n", "\n", "# Reset step count used for recording of summaries (see above cell).\n", "tf.train.get_or_create_global_step().assign(0);"], "execution_count": null, "outputs": []}, {"metadata": {"id": "Z329SZSAZiWO", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Forwarding of TensorBoard's 6006 port using https://ngrok.com\n", "\n", "# Download & unzip ngrok\n", "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n", "!unzip -o ngrok-stable-linux-amd64.zip\n", "!ls -lh ./ngrok\n", "!pkill tensorboard; pkill ngrok\n", "\n", "# Start TensorBoard\n", "get_ipython().system_raw(\n", "    'tensorboard --logdir \"{}\" --host 0.0.0.0 --port 6006 &'\n", "    .format(os.path.dirname(tensorboard_path))\n", ")\n", "# Forward port.\n", "get_ipython().system_raw('./ngrok http 6006 &')\n", "# Give some time to start up.\n", "!sleep 1\n", "# Output external address (ngrok's web interface listens at 4004).\n", "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""], "execution_count": null, "outputs": []}, {"metadata": {"id": "-USh58Jp-_zD", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# First open TensorBoard in a seaprate tab by clicking on above link ^^.\n", "\n", "# Then let's create a new model and train it again.\n", "# Check out TensorBoard during training (click on the \"refresh\" button to see\n", "# new data).\n", "history = lstm_model.fit(ds_stroke, steps_per_epoch=steps_per_epoch, epochs=1, callbacks=callbacks)"], "execution_count": null, "outputs": []}, {"metadata": {"id": "6H9c7uDLi45c", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# Summaries are stored as \"events.out.tfevents.*\" files.\n", "# BTW you can also parse these data programatically using\n", "# tf.train.summary_iterator()\n", "!find $tensorboard_path"], "execution_count": null, "outputs": []}, {"metadata": {"id": "kMXOYejJ2ylo", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["# YOUR ACTION REQUIRED:\n", "# Re-run this entire section, but provide a different subdirectory name\n", "# for \"tensorboard_path\" (e.g. \"lstm2\" instead of the original \"lstm1\").\n", "# Use TensorBoard to compare the different runs. This exercise is especially\n", "# interesting if you also change some model parameters (try changing the cell\n", "# size or adding some Dense layers at the end, for example)."], "execution_count": null, "outputs": []}, {"metadata": {"id": "ygOHM1PApo0a", "colab_type": "text"}, "cell_type": "markdown", "source": ["## More shape manipulation"]}, {"metadata": {"id": "jdTdZ-K0X_K2", "colab_type": "text"}, "cell_type": "markdown", "source": ["So you think shapes are easy, right? Well... Then here we go with a real-world shape challenge!\n", "\n", "(You probably won't have time to finish this challenge during the workshop; come back to this later and don't feel bad about consulting the solution...)\n", "\n", " Imagine you have a recurrent neural network that outputs a \"sequence\"\n", " tensor with dimension [?, max_len, ?], where\n", " \n", "*   the first (dynamic) dimension is the number of elements in the batch\n", "*   the second dimension is the maximum sequence length\n", "*   the third (dynamic) dimension is the number of number per element\n", "\n", "The actual length of every sequence in the batch (<= max_len) is also\n", " specified in the tensor `lens` (length=number of elements in batch).\n", "\n", " The task at hand is to extract the `nth` element of every sequence.\n", " The resulting tensor `last_elements` should have the shape `[?, ?]`,\n", " matching the first and third dimension of tensor `sequence`.\n", "\n", "** Hint:** The idea is to reshape the \"sequence\" to \"partially_flattened\"\n", " and then construct a \"idxs\" tensor (within this partially flattened\n", " tensor) that returns the requested elements.\n", "\n", " Handy functions:\n", " \n", "*   `tf.gather()`\n", "*   `tf.range()`\n", "*   `tf.reshape()`\n", "*   `tf.shape()`\n"]}, {"metadata": {"id": "LbXByWGy3Yc_", "colab_type": "code", "colab": {}}, "cell_type": "code", "source": ["max_len = 5\n", "sequences = tf.constant([\n", "    [[1,1], [1,1], [2,2], [0,0], [0,0]],\n", "    [[1,1], [1,1], [1,1], [3,3], [0,0]],\n", "    [[1,1], [1,1], [1,1], [1,1], [4,4]],\n", "])\n", "lens = tf.constant([3, 4, 5])\n", "\n", "# YOUR ACTION REQUIRED:\n", "# Find the correct expression for below tensors.\n", "# (Check out the ../solutions/3_eager.ipynb Colab if you get stuck...)\n", "\n", "batch_size = \n", "hidden_state_size = \n", "idxs = \n", "\n", "partially_flattened =\n", "last_elements =\n", "\n", "print(last_elements)\n", "\n"], "execution_count": null, "outputs": []}]}